{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFLX Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top10 = pd.read_excel('Data Specialist NFLX Data.xlsx',sheet_name='NFLX Top 10')\n",
    "df_imdb = pd.read_excel('Data Specialist NFLX Data.xlsx',sheet_name='IMDB Rating')\n",
    "df_runtime = pd.read_excel('Data Specialist NFLX Data.xlsx',sheet_name='Runtime')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 520 entries, 0 to 519\n",
      "Data columns (total 8 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   date_added                  520 non-null    datetime64[ns]\n",
      " 1   week                        520 non-null    datetime64[ns]\n",
      " 2   category                    520 non-null    object        \n",
      " 3   show_title                  520 non-null    object        \n",
      " 4   season_title                249 non-null    object        \n",
      " 5   weekly_rank                 520 non-null    int64         \n",
      " 6   cumulative_weeks_in_top_10  520 non-null    int64         \n",
      " 7   weekly_hours_viewed         520 non-null    int64         \n",
      "dtypes: datetime64[ns](2), int64(3), object(3)\n",
      "memory usage: 32.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_top10.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15879 entries, 0 to 15878\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   title   14569 non-null  object \n",
      " 1   rating  15879 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 248.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_imdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15879 entries, 0 to 15878\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    14569 non-null  object\n",
      " 1   runtime  15879 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 248.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_runtime.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtime= df_runtime.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Life                       5\n",
       "The Gift                   4\n",
       "The Bodyguard              3\n",
       "Death Note                 3\n",
       "Tiger                      3\n",
       "                          ..\n",
       "My Liberation Notes        1\n",
       "Radhe Shyam (Hindi)        1\n",
       "Rambo: Last Blood          1\n",
       "Raw (Hindi)                1\n",
       "Retfærdighedens ryttere    1\n",
       "Name: count, Length: 14226, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_runtime['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtime = df_runtime.drop_duplicates(subset='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system we use to collect data from the Netflix website experienced an issue during the\n",
    " week of May22nd, 2022, specifically affecting the 'weekly_hours_viewed' column. All other\n",
    " columns were accurately collected. Due to this, we cannot use this week in our estimates, as the\n",
    " 'weekly_hours_viewed' column is critical for tracking viewership metrics. You can assume that\n",
    " this is the only week with incomplete viewership data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows when the week is on 2022/05/22\n",
    "df_top10 = df_top10[df_top10['week'] != '2022-05-22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────────────────┐\n",
       "│        week         │\n",
       "│    timestamp_ns     │\n",
       "├─────────────────────┤\n",
       "│ 2022-05-08 00:00:00 │\n",
       "│ 2022-06-26 00:00:00 │\n",
       "│ 2022-04-10 00:00:00 │\n",
       "│ 2022-06-19 00:00:00 │\n",
       "│ 2022-04-24 00:00:00 │\n",
       "│ 2022-04-17 00:00:00 │\n",
       "│ 2022-06-12 00:00:00 │\n",
       "│ 2022-05-01 00:00:00 │\n",
       "│ 2022-04-03 00:00:00 │\n",
       "│ 2022-05-15 00:00:00 │\n",
       "│ 2022-05-29 00:00:00 │\n",
       "│ 2022-06-05 00:00:00 │\n",
       "├─────────────────────┤\n",
       "│       12 rows       │\n",
       "└─────────────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "query = '''select distinct week from df_top10\n",
    "'''\n",
    "\n",
    "duckdb.sql(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the ‘Films (English)’ category, which film has the most appearances in our data set\n",
    " (NFLX Top 10 tab of the Sheet)? What were its average weekly hours viewed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────────────────┬─────────────────┬───────────────┐\n",
       "│     show_title     │ title_frequency │ average_views │\n",
       "│      varchar       │      int64      │    double     │\n",
       "├────────────────────┼─────────────────┼───────────────┤\n",
       "│ Sonic the Hedgehog │               8 │     7481250.0 │\n",
       "└────────────────────┴─────────────────┴───────────────┘"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "query = '''\n",
    "select\n",
    "  show_title\n",
    " ,count(show_title) as title_frequency\n",
    " ,avg(weekly_hours_viewed) as average_views\n",
    " from df_top10\n",
    " where category = 'Films (English)'\n",
    " group by show_title\n",
    " order by 2 desc\n",
    " limit 1\n",
    "'''\n",
    "\n",
    "duckdb.sql(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the 'Films (English)' category, which film has the lowest IMDb rating? What were its\n",
    " average weekly hours viewed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────────────────┬─────────────────┬───────────────┬────────┐\n",
       "│     show_title     │    category     │ average_views │ rating │\n",
       "│      varchar       │     varchar     │    double     │ double │\n",
       "├────────────────────┼─────────────────┼───────────────┼────────┤\n",
       "│ 365 Days: This Day │ Films (English) │    29022500.0 │    2.5 │\n",
       "└────────────────────┴─────────────────┴───────────────┴────────┘"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = '''\n",
    "select\n",
    "  a.show_title\n",
    " ,a.category\n",
    " ,avg(a.weekly_hours_viewed) as average_views\n",
    " ,b.rating\n",
    "from df_top10 a\n",
    " join df_imdb b\n",
    "  on a.show_title = b.title\n",
    "where a.category = 'Films (English)' and b.rating > 0\n",
    "group by a.show_title, b.rating, a.category\n",
    "order by b.rating asc\n",
    "limit 1\n",
    "'''\n",
    "\n",
    "duckdb.sql(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In the 'Films (Non-English)' category, which film has spent the most weeks in the top 10?\n",
    " To estimate the number of users who watched this film, what assumptions would you\n",
    " make andwhat risks are involved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────────────┬────────────────────────────┐\n",
       "│    show_title     │ cumulative_weeks_in_top_10 │\n",
       "│      varchar      │           int64            │\n",
       "├───────────────────┼────────────────────────────┤\n",
       "│ Through My Window │                         13 │\n",
       "└───────────────────┴────────────────────────────┘"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "select\n",
    "     show_title\n",
    "    ,cumulative_weeks_in_top_10\n",
    "    from df_top10\n",
    "    where category = 'Films (Non-English)'\n",
    "    order by 2 desc\n",
    "    limit 1\n",
    "'''\n",
    "\n",
    "duckdb.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────────────┬──────────────────────┬─────────┬───────────────┐\n",
       "│    show_title     │ total_minutes_viewed │ runtime │ total_watched │\n",
       "│      varchar      │        int128        │  int64  │    double     │\n",
       "├───────────────────┼──────────────────────┼─────────┼───────────────┤\n",
       "│ Through My Window │             90000000 │     116 │      775862.0 │\n",
       "└───────────────────┴──────────────────────┴─────────┴───────────────┘"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "query = '''\n",
    "select\n",
    "     a.show_title\n",
    "    ,a.total_minutes_viewed\n",
    "    ,b.runtime\n",
    "    ,floor(a.total_minutes_viewed / b.runtime) as total_watched\n",
    "from\n",
    "(\n",
    "select\n",
    "     show_title\n",
    "    ,cumulative_weeks_in_top_10\n",
    "    ,sum(weekly_hours_viewed) * 60 as total_minutes_viewed\n",
    "    from df_top10\n",
    "    where category = 'Films (Non-English)'\n",
    "    group by show_title, cumulative_weeks_in_top_10\n",
    "    order by 2 desc\n",
    "    limit 1\n",
    ") a\n",
    "join df_runtime b\n",
    "on a.show_title = b.title\n",
    "\n",
    "\n",
    "'''\n",
    "duckdb.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this film has been watched 775862 times. Assuming it was watched once by every single user, it had 775862 users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 4 .Whatarethe risks of ignoring the data from the week of May 22nd when calculating the\n",
    " metrics from the previous questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The week was removed due to the issue with the weekly_hours_viewed field. This removal could affect the analysis if a film during this week was on the list of most-watched films, or if a film from this week had more weeks in the top 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. While we've indicated that the 'weekly_hours_viewed' data for the week of May 22nd\n",
    " cannot be used in our estimates, we may want to fill in this missing information for other\n",
    " analyses. As a Data Specialist, what methodology would you propose to estimate the\n",
    " 'weekly_hours_viewed' for this missing week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One of the first approaches would be to examine the\n",
    "# behavior of the weekly_hours_viewed data before and\n",
    "# after the missing week. Using the mean or median of adjacent weeks,\n",
    "# I could generate an estimate for the week of May 22nd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
